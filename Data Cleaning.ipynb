{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d86525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clntnum</th>\n",
       "      <th>race_desc</th>\n",
       "      <th>ctrycode_desc</th>\n",
       "      <th>clttype</th>\n",
       "      <th>stat_flag</th>\n",
       "      <th>min_occ_date</th>\n",
       "      <th>cltdob_fix</th>\n",
       "      <th>cltsex_fix</th>\n",
       "      <th>flg_substandard</th>\n",
       "      <th>flg_is_borderline_standard</th>\n",
       "      <th>...</th>\n",
       "      <th>recency_giclaim</th>\n",
       "      <th>giclaim_cnt_success</th>\n",
       "      <th>recency_giclaim_success</th>\n",
       "      <th>giclaim_cnt_unsuccess</th>\n",
       "      <th>recency_giclaim_unsuccess</th>\n",
       "      <th>flg_gi_claim_29d435_ever</th>\n",
       "      <th>flg_gi_claim_058815_ever</th>\n",
       "      <th>flg_gi_claim_42e115_ever</th>\n",
       "      <th>flg_gi_claim_856320_ever</th>\n",
       "      <th>f_purchase_lh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>91b546e924</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>1974-05-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>896bae548c</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>1979-11-11</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>f364439ae6</td>\n",
       "      <td>Others</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>1976-01-28</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>70f319cfe1</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>1976-03-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19724</th>\n",
       "      <td>2647a81328</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>1995-07-31</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          clntnum race_desc ctrycode_desc clttype stat_flag min_occ_date  \\\n",
       "19550  91b546e924   Chinese     Singapore       P    ACTIVE   2017-10-31   \n",
       "4600   896bae548c   Chinese     Singapore       P    ACTIVE   2007-05-23   \n",
       "13337  f364439ae6    Others     Singapore       P    ACTIVE   2019-08-31   \n",
       "15074  70f319cfe1   Chinese     Singapore       P    ACTIVE   2021-10-18   \n",
       "19724  2647a81328   Chinese     Singapore       P    ACTIVE   2018-07-20   \n",
       "\n",
       "       cltdob_fix cltsex_fix  flg_substandard  flg_is_borderline_standard  \\\n",
       "19550  1974-05-09     Female              0.0                         0.0   \n",
       "4600   1979-11-11       Male              0.0                         0.0   \n",
       "13337  1976-01-28       Male              0.0                         0.0   \n",
       "15074  1976-03-19     Female              0.0                         0.0   \n",
       "19724  1995-07-31     Female              0.0                         0.0   \n",
       "\n",
       "       ...  recency_giclaim  giclaim_cnt_success  recency_giclaim_success  \\\n",
       "19550  ...              NaN                 None                     None   \n",
       "4600   ...              NaN                 None                     None   \n",
       "13337  ...              NaN                 None                     None   \n",
       "15074  ...              NaN                 None                     None   \n",
       "19724  ...              NaN                 None                     None   \n",
       "\n",
       "       giclaim_cnt_unsuccess  recency_giclaim_unsuccess  \\\n",
       "19550                   None                       None   \n",
       "4600                    None                       None   \n",
       "13337                   None                       None   \n",
       "15074                   None                       None   \n",
       "19724                   None                       None   \n",
       "\n",
       "       flg_gi_claim_29d435_ever  flg_gi_claim_058815_ever  \\\n",
       "19550                      None                      None   \n",
       "4600                       None                      None   \n",
       "13337                      None                      None   \n",
       "15074                      None                      None   \n",
       "19724                      None                      None   \n",
       "\n",
       "       flg_gi_claim_42e115_ever  flg_gi_claim_856320_ever  f_purchase_lh  \n",
       "19550                      None                      None            NaN  \n",
       "4600                       None                      None            NaN  \n",
       "13337                      None                      None            NaN  \n",
       "15074                      None                      None            NaN  \n",
       "19724                      None                      None            NaN  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('./data/catB_train.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60e00b",
   "metadata": {},
   "source": [
    "### General Client Information  \n",
    "• clntnum: Unique identifier for the client.  \n",
    "• race_desc: Description of the client's race.  \n",
    "• ctrycode_desc: Country code indicating the client's location.  \n",
    "• clttype: Customer status.  \n",
    "• **stat_flag**: Flag indicating ACTIVE, LAPSED or MATURED. E.g. if there’s at least one inforce policy, then the flag would be ACTIVE. If all of the client’s policies are all lapsed, then it is LAPSED.  \n",
    "• min_occ_date: Date of the client's first interaction or policy purchase with the company.  \n",
    "• **cltdob_fix**: Fixed or corrected date of birth of the client.  \n",
    "• **cltsex_fix**: Fixed or corrected gender of the client.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d0b3acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 17992\n",
      "Number of columns: 304\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df.shape\n",
    "df.head()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66883f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACTIVE', 'LAPSED', 'MATURED'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count classes of categorical variables\n",
    "set(df['stat_flag'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4efe332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check presence of missing value\n",
    "sum(pd.isnull(df['stat_flag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0aa975ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19550     144\n",
      "4600      153\n",
      "13337      62\n",
      "15074       1\n",
      "19724     114\n",
      "         ... \n",
      "11284      85\n",
      "11964       0\n",
      "5390       43\n",
      "860        72\n",
      "15795    None\n",
      "Name: hh_20, Length: 17992, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['hh_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c85b5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.ABOVE200K', 'B.100K-200K', 'C.60K-100K', 'D.30K-60K', 'E.BELOW30K', None}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['annual_income_est'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef05247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'G', 'P'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['clttype'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4110c",
   "metadata": {},
   "source": [
    "### Client Risk and Status Indicators  \n",
    "• flg_substandard: Flag for substandard risk clients.  \n",
    "• flg_is_borderline_standard: Flag for borderline standard risk clients.  \n",
    "• flg_is_revised_term: Flag if customer ever has revised terms.  \n",
    "• flg_is_rental_flat: Indicates if the client lives in a rental flat.  \n",
    "• flg_has_health_claim: Flag for clients with health insurance claims.  \n",
    "• flg_has_life_claim: Flag for clients with life insurance claims.  \n",
    "• flg_gi_claim: Flag for general insurance claims.  \n",
    "• flg_is_proposal: Indicates if there is a policy in proposal for client.  \n",
    "• flg_with_preauthorisation: Flag for clients with preauthorized transactions or policies.  \n",
    "• flg_is_returned_mail: Flag for returned mail instances.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554da87",
   "metadata": {},
   "source": [
    "### Demographic and Household Information  \n",
    "• is_housewife_retiree, is_sg_pr, is_class_1_2: Flags indicating specific demographics like occupation, residency status, etc.  \n",
    "• is_dependent_in_at_least_1_policy: Indicates if the client is a dependent in at least one policy.  \n",
    "• hh_20, pop_20, hh_size, hh_size_est: Metrics related to household size and population.  \n",
    "• annual_income_est: Estimated annual income of the client, in buckets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda49479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9efc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type for is_housewife_retiree: float64\n",
      "Count of missing data for is_housewife_retiree: 1014\n",
      "Count of is_housewife_retiree being True (1): 54\n",
      "Count of is_housewife_retiree being False (0): 16924\n",
      "Unique values for is_housewife_retiree: {0.0, 1.0}\n",
      "Data type for is_sg_pr: float64\n",
      "Count of missing data for is_sg_pr: 1014\n",
      "Count of is_sg_pr being True (1): 15593\n",
      "Count of is_sg_pr being False (0): 1385\n",
      "Unique values for is_sg_pr: {0.0, 1.0}\n",
      "Data type for is_class_1_2: float64\n",
      "Count of missing data for is_class_1_2: 1014\n",
      "Count of is_class_1_2 being True (1): 9051\n",
      "Count of is_class_1_2 being False (0): 7927\n",
      "Unique values for is_class_1_2: {0.0, 1.0}\n",
      "Data type for is_dependent_in_at_least_1_policy: float64\n",
      "Count of missing data for is_dependent_in_at_least_1_policy: 1014\n",
      "Count of is_dependent_in_at_least_1_policy being True (1): 0\n",
      "Count of is_dependent_in_at_least_1_policy being False (0): 16978\n",
      "Unique values for is_dependent_in_at_least_1_policy: {0.0}\n"
     ]
    }
   ],
   "source": [
    "def analyze_binary_variable(df, column_name):\n",
    "    print(f\"Data type for {column_name}: {df[column_name].dtype}\")\n",
    "    # Print count of missing data\n",
    "    print(f\"Count of missing data for {column_name}: {sum(pd.isnull(df[column_name]))}\")\n",
    "\n",
    "    # Filter rows without missing values\n",
    "    df_no_missing = df[df[column_name].notnull()]\n",
    "\n",
    "    # Display count of each value\n",
    "    count_true = (df[column_name] == 1).sum()\n",
    "    count_false = (df[column_name] == 0).sum()\n",
    "    print(f\"Count of {column_name} being True (1): {count_true}\")\n",
    "    print(f\"Count of {column_name} being False (0): {count_false}\")\n",
    "\n",
    "    # Display unique values in the filtered DataFrame\n",
    "    unique_values = set(df_no_missing[column_name].values.tolist())\n",
    "    print(f\"Unique values for {column_name}: {unique_values}\")\n",
    "analyze_binary_variable(df, 'is_housewife_retiree')\n",
    "analyze_binary_variable(df, 'is_sg_pr')\n",
    "analyze_binary_variable(df, 'is_class_1_2')\n",
    "analyze_binary_variable(df, 'is_dependent_in_at_least_1_policy')\n",
    "\n",
    "def analyze_numerical_variable(df, column_name):\n",
    "    print(f\"Data type for {column_name}: {df[column_name].dtype}\")\n",
    "    # Print count of missing data\n",
    "    print(f\"Count of missing data for {column_name}: {sum(pd.isnull(df[column_name]))}\")\n",
    "\n",
    "    # Filter rows without missing values\n",
    "    df_no_missing = df[df[column_name].notnull()]\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    # Calculate mean\n",
    "    result['mean'] = df_no_missing[column_name].mean()\n",
    "\n",
    "    # Calculate median\n",
    "    result['median'] = df_no_missing[column_name].median()\n",
    "\n",
    "    # Calculate mode (using scipy.stats.mode as pandas mode can return multiple modes)\n",
    "    result['mode'] = stats.mode(df_no_missing[column_name]).mode[0]\n",
    "\n",
    "    # Calculate variance using pandas\n",
    "    result['variance'] = df_no_missing[column_name].var()\n",
    "\n",
    "    # Detect outliers using the IQR method\n",
    "    Q1 = df_no_missing[column_name].quantile(0.25)\n",
    "    Q3 = df_no_missing[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df_no_missing[(df_no_missing[column_name] < lower_bound) | (df_no_missing[column_name] > upper_bound)]\n",
    "    result['outlier# Print the resultss'] = outliers\n",
    "    \n",
    "    # print(f\"Mean: {result_dict['mean']}\")\n",
    "    #print(f\"Median: {result_dict['median']}\")\n",
    "    #print(f\"Mode: {result_dict['mode']}\")\n",
    "    #print(f\"Variance: {result_dict['variance']}\")\n",
    "    #print(\"\\nOutliers:\")\n",
    "    #print(result_dict['outliers'])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7625d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data: 1014\n",
      "Count of not retired housewife: 16924\n",
      "Count of retired housewife: 54\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 17992 entries, 19550 to 15795\n",
      "Series name: is_housewife_retiree\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "16978 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 281.1 KB\n"
     ]
    }
   ],
   "source": [
    "# is_housewife_retiree\n",
    "\n",
    "print(f\"Count of missing data: {sum(pd.isnull(df['is_housewife_retiree']))}\") \n",
    "# Display rows without missing values\n",
    "df_no_missing = df[df['is_housewife_retiree'].notnull()]\n",
    "\n",
    "# Now, df_no_missing contains only the rows without missing values\n",
    "result = df_no_missing.loc[:, ['is_housewife_retiree']]\n",
    "count_no_missing = (df['is_housewife_retiree'] == 0).sum()\n",
    "count_housewife = (df['is_housewife_retiree'] == 1).sum()\n",
    "print(f\"Count of not retired housewife: {count_no_missing}\")\n",
    "print(f\"Count of retired housewife: {count_housewife}\")\n",
    "df['is_housewife_retiree'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f89640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data: 1014\n",
      "Count of not_pr: 1385\n",
      "Count of pr: 15593\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 17992 entries, 19550 to 15795\n",
      "Series name: is_sg_pr\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "16978 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 281.1 KB\n"
     ]
    }
   ],
   "source": [
    "# is_sg_pr\n",
    "print(f\"Count of missing data: {sum(pd.isnull(df['is_sg_pr']))}\") \n",
    "# Display rows without missing values\n",
    "df_no_missing_pr = df[df['is_sg_pr'].notnull()]\n",
    "\n",
    "# Now, df_no_missing contains only the rows without missing values\n",
    "result = df_no_missing_pr.loc[:, ['is_sg_pr']].sum()\n",
    "count_not_pr = (df['is_sg_pr'] == 0).sum()\n",
    "count_pr = (df['is_sg_pr'] == 1).sum()\n",
    "print(f\"Count of not_pr: {count_not_pr}\")\n",
    "print(f\"Count of pr: {count_pr}\")\n",
    "df['is_sg_pr'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f7a2731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data: 1014\n",
      "Count of class 2: 9051\n",
      "Count of class 1: 7927\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 17992 entries, 19550 to 15795\n",
      "Series name: is_class_1_2\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "16978 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 281.1 KB\n"
     ]
    }
   ],
   "source": [
    "# is_class_1_2\n",
    "print(f\"Count of missing data: {sum(pd.isnull(df['is_class_1_2']))}\") \n",
    "\n",
    "# Display rows without missing values\n",
    "df_no_missing_class = df[df['is_class_1_2'].notnull()]\n",
    "\n",
    "# Now, df_no_missing contains only the rows without missing values\n",
    "result = df_no_missing_class.loc[:, ['is_class_1_2']]\n",
    "# set(df_no_missing_class['is_class_1_2'].values.tolist())\n",
    "count_class_2 = (df['is_class_1_2'] == 1).sum()\n",
    "count_class_1 = (df['is_class_1_2'] == 0).sum()\n",
    "print(f\"Count of class 2: {count_class_2}\")\n",
    "print(f\"Count of class 1: {count_class_1}\")\n",
    "df['is_class_1_2'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ebc1ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data: 1014\n",
      "Count of dependent: 0\n",
      "Count of independent: 16978\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 17992 entries, 19550 to 15795\n",
      "Series name: is_dependent_in_at_least_1_policy\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "16978 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 281.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is_dependent_in_at_least_1_policy\n",
    "print(f\"Count of missing data: {sum(pd.isnull(df['is_dependent_in_at_least_1_policy']))}\") \n",
    "\n",
    "# Display rows without missing values\n",
    "df_no_missing_dependency = df[df['is_dependent_in_at_least_1_policy'].notnull()]\n",
    "\n",
    "# Now, df_no_missing contains only the rows without missing values\n",
    "result = df_no_missing_dependency.loc[:, ['is_dependent_in_at_least_1_policy']]\n",
    "# set(df_no_missing_class['is_class_1_2'].values.tolist())\n",
    "count_dependent = (df['is_dependent_in_at_least_1_policy'] == 1).sum()\n",
    "count_independent = (df['is_dependent_in_at_least_1_policy'] == 0).sum()\n",
    "print(f\"Count of dependent: {count_dependent}\")\n",
    "print(f\"Count of independent: {count_independent}\")\n",
    "df['is_dependent_in_at_least_1_policy'].info()\n",
    "set(df_no_missing_dependency['is_dependent_in_at_least_1_policy'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be0879d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data: 2809\n",
      "Count of ABOVE200K: 2097\n",
      "Count of 100K-200K: 725\n",
      "Count of 60K-100K: 2679\n",
      "Count of 30K-60K: 1911\n",
      "Count of BELOW30K: 7771\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 17992 entries, 19550 to 15795\n",
      "Series name: annual_income_est\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "15183 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 281.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A.ABOVE200K', 'B.100K-200K', 'C.60K-100K', 'D.30K-60K', 'E.BELOW30K'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# annual_income_est\n",
    "print(f\"Count of missing data: {sum(pd.isnull(df['annual_income_est']))}\") \n",
    "\n",
    "# Display rows without missing values\n",
    "df_no_missing_income = df[df['annual_income_est'].notnull()]\n",
    "\n",
    "# Now, df_no_missing contains only the rows without missing values\n",
    "result = df_no_missing_income.loc[:, ['annual_income_est']]\n",
    "# set(df_no_missing_class['is_class_1_2'].values.tolist())\n",
    "count_A = (df_no_missing_income['annual_income_est'].str.split('.').str[0] == 'A').sum()\n",
    "count_B = (df_no_missing_income['annual_income_est'].str.split('.').str[0] == 'B').sum()\n",
    "count_C = (df_no_missing_income['annual_income_est'].str.split('.').str[0] == 'C').sum()\n",
    "count_D = (df_no_missing_income['annual_income_est'].str.split('.').str[0] == 'D').sum()\n",
    "count_E = (df_no_missing_income['annual_income_est'].str.split('.').str[0] == 'E').sum()\n",
    "print(f\"Count of ABOVE200K: {count_A}\")\n",
    "print(f\"Count of 100K-200K: {count_B}\")\n",
    "print(f\"Count of 60K-100K: {count_C}\")\n",
    "print(f\"Count of 30K-60K: {count_D}\")\n",
    "print(f\"Count of BELOW30K: {count_E}\")\n",
    "df['annual_income_est'].info()\n",
    "set(df_no_missing_dependency['annual_income_est'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2fb573d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ABOVE200K: 141\n",
      "Count of 100K-200K: 43\n",
      "Count of 60K-100K: 140\n",
      "Count of 30K-60K: 80\n",
      "Count of BELOW30K: 287\n"
     ]
    }
   ],
   "source": [
    "# f_purchase_lh\n",
    "df_no_missing_purchase = df[df['f_purchase_lh'].notnull()]\n",
    "result = df_no_missing_purchase.loc[:, ['annual_income_est']]\n",
    "count_A = (df_no_missing_purchase['annual_income_est'].str.split('.').str[0] == 'A').sum()\n",
    "count_B = (df_no_missing_purchase['annual_income_est'].str.split('.').str[0] == 'B').sum()\n",
    "count_C = (df_no_missing_purchase['annual_income_est'].str.split('.').str[0] == 'C').sum()\n",
    "count_D = (df_no_missing_purchase['annual_income_est'].str.split('.').str[0] == 'D').sum()\n",
    "count_E = (df_no_missing_purchase['annual_income_est'].str.split('.').str[0] == 'E').sum()\n",
    "print(f\"Count of ABOVE200K: {count_A}\")\n",
    "print(f\"Count of 100K-200K: {count_B}\")\n",
    "print(f\"Count of 60K-100K: {count_C}\")\n",
    "print(f\"Count of 30K-60K: {count_D}\")\n",
    "print(f\"Count of BELOW30K: {count_E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdeb4ae",
   "metadata": {},
   "source": [
    "### Policy and Claim History  \n",
    "• n_months_last_bought_products, flg_latest_being_lapse, flg_latest_being_cancel, recency_lapse, recency_cancel: Metrics related to the recency of policy purchases, lapses, and cancellations.  \n",
    "• tot_inforce_pols, tot_cancel_pols: Total number of in-force and canceled policies.  \n",
    "• f_ever_declined_la: Flag for clients has ever been declined policies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866136cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73094979",
   "metadata": {},
   "source": [
    "### Anonymized Insurance Product Metrics (APE, Sum Insured, Prepaid Premiums)  \n",
    "• ape_, sumins_, prempaid_* (e.g., ape_gi_42e115, sumins_ltc_1280bf, prempaid_grp_6fc3e6): Metrics for various anonymized insurance products, likely representing different types of policies like general insurance, long-term care, group policies, etc. The suffixes (like 42e115, 1280bf) are unique identifiers for the specific insurance products. ‘ape’ stands for Annual Premium Equivalent, 'sumins' for sum insured, ‘prempaid’ stands for premium customers will pay from product inception to product maturity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc8849",
   "metadata": {},
   "source": [
    "### Other Flags and Metrics  \n",
    "• f_elx, f_mindef_mha, f_retail: Flags possibly related to client's association with specific programs or sectors.  \n",
    "• flg_affconnect_*, affcon_visit_days, n_months_since_visit_affcon: Metrics related to client’s activity in affinity connect.  \n",
    "• clmcon_visit_days, recency_clmcon, recency_clmcon_regis: Metrics related to client’s activity in claim connect.  \n",
    "• hlthclaim_amt, giclaim_amt, recency_hlthclaim, recency_giclaim, hlthclaim_cnt_success, giclaim_cnt_success: Health and general insurance claim-related metrics.  \n",
    "• flg_hlthclaim_, flg_gi_claim_ (e.g., flg_hlthclaim_839f8a_ever, flg_gi_claim_29d435_ever): Flags for specific types of health and general insurance claims, with anonymized identifiers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee704423",
   "metadata": {},
   "source": [
    "### Purchase and Lapse Metrics for Specific Products  \n",
    "• f_ever_bought_, n_months_last_bought_, lapse_ape_, n_months_since_lapse_ (e.g., f_ever_bought_839f8a, n_months_last_bought_grp_6fc3e6, lapse_ape_ltc_1280bf, n_months_since_lapse_inv_dcd836): Flags and metrics indicating purchase history, lapses, and time since last interaction for various anonymized insurance products.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
