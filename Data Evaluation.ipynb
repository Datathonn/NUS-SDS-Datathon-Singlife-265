{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2e3a3e-033f-489a-85bb-e0a0c9fcbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_parquet('./data/catB_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59690688-732a-4fa8-bb86-6b70343db401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature Age\n",
    "df = df[df['cltdob_fix']!='None']\n",
    "df['cltdob_fix'] = pd.to_datetime(df.iloc[:, 6], format ='mixed')\n",
    "df['age'] = 2024-df['cltdob_fix'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5af145-8305-4539-acbe-7284e8d4c8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11984\\1821917785.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['annual_income_est'] = df['annual_income_est'].replace(mapping)\n"
     ]
    }
   ],
   "source": [
    "# Mapping for replacement for categorical data (not hot encoding)\n",
    "mapping = {\n",
    "    None: -1,\n",
    "    'E.BELOW30K': 0,\n",
    "    'D.30K-60K': 1,\n",
    "    'C.60K-100K': 2,\n",
    "    'B.100K-200K': 3,\n",
    "    'A.ABOVE200K': 4,\n",
    "}\n",
    "\n",
    "# Replace values based on the mapping\n",
    "df['annual_income_est'] = df['annual_income_est'].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a924ca-d8eb-4685-ba9c-84cadde663ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Column\n",
    "df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].fillna(0)\n",
    "y = df[\"f_purchase_lh\"]\n",
    "\n",
    "# All features \n",
    "X = df.drop(columns=['f_purchase_lh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d032128-9c1d-4615-b943-0a1eaac4ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split numerical and non-numerical columns\n",
    "numeric_cols = X.select_dtypes(include=[\"int32\", \"int64\", \"float64\"]).columns\n",
    "X_numeric = X[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ef7523-9978-47af-b080-94b892c8a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Low-Variance Numerical Variables\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(0.05))\n",
    "sel.fit(X_numeric)\n",
    "X_numeric = X_numeric[numeric_cols[sel.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "851cf756-2105-4959-b981-ee2a72490bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in numeric columns with the median value\n",
    "X_numeric = X_numeric.apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36fd0adf-85be-4243-841c-0a0204c78876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with selected non_categorical values\n",
    "temp = pd.get_dummies(X[['cltsex_fix', 'stat_flag']], dtype=float)\n",
    "X = pd.concat([X_numeric, temp, df['age']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84edbbe-6f1c-467f-85a3-e4fe8500f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17970\n",
      "708.0\n",
      "3.9398998330550916%\n"
     ]
    }
   ],
   "source": [
    "# Test whether it's imbalanced case\n",
    "total_row = len(y)\n",
    "purchase = sum(y)\n",
    "non_purchase = total_row - purchase\n",
    "percentage_of_purchase = (purchase/total_row)*100\n",
    "print(total_row)\n",
    "print(purchase)\n",
    "print(f\"{percentage_of_purchase}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63746541-bb52-4087-a25c-74f402151e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Counter({0.0: 13814, 1.0: 562})\n",
      "After: Counter({0.0: 13843, 1.0: 13776})\n"
     ]
    }
   ],
   "source": [
    "# use SMOTE/adasyn to handle imbalance\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\n",
    "\n",
    "adasyn = ADASYN(random_state=0)\n",
    "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train_smote, X_val_smote, y_train_smote, y_val_smote = train_test_split(X_resampled_smote, y_resampled_smote, test_size=0.2, random_state=0)\n",
    "X_train_adasyn, X_val_adasyn, y_train_adasyn, y_val_adasyn = train_test_split(X_resampled_adasyn, y_resampled_adasyn, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de057a3-8e95-430b-8357-3d8ae412de55",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc51481-28c2-4c5a-87bc-2f76a10c526e",
   "metadata": {},
   "source": [
    "1. compare different feature ranking method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83cdbee-a467-49c2-8d75-674d51cd551e",
   "metadata": {},
   "source": [
    "** this code take extremely long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "918364f9-0a13-4a83-9677-015184cc17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "Accuracy: 0.800222593210907\n",
      "Confusion Matrix:\n",
      "[[2811  637]\n",
      " [  81   65]]\n",
      "F1 Score: 0.15330188679245282\n",
      "Precision: 0.09259259259259259\n",
      "Recall: 0.4452054794520548\n",
      "\n",
      "filtered_mutual_info:\n",
      "Accuracy: 0.6457985531441292\n",
      "Confusion Matrix:\n",
      "[[2222 1226]\n",
      " [  47   99]]\n",
      "F1 Score: 0.13460231135282122\n",
      "Precision: 0.07471698113207548\n",
      "Recall: 0.678082191780822\n",
      "\n",
      "filtered_rfe:\n",
      "Accuracy: 0.6477462437395659\n",
      "Confusion Matrix:\n",
      "[[2222 1226]\n",
      " [  40  106]]\n",
      "F1 Score: 0.14343707713125844\n",
      "Precision: 0.07957957957957958\n",
      "Recall: 0.726027397260274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,precision_score, recall_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# a. mutual info\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mutual_info_values = mutual_info_classif(X, y, discrete_features=[False]*X.shape[1])\n",
    "threshold = 0.005\n",
    "selected_features_mutualinfo = X.columns[mutual_info_values > threshold]\n",
    "\n",
    "# b. RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize RFE with the classifier and the number of features to retain\n",
    "num_features_to_keep = 25\n",
    "rfe = RFE(estimator=classifier, n_features_to_select=num_features_to_keep)\n",
    "\n",
    "# Fit RFE to the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_rfe = X_train.columns[rfe.support_]\n",
    "\n",
    "\n",
    "# train model using smote and adasyn\n",
    "def train(selected_features):\n",
    "    X_new = X[selected_features]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_new, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_resampled_smote, y_resampled_smote = smote.fit_resample(X_new, y)\n",
    "\n",
    "    adasyn = ADASYN(random_state=0)\n",
    "    X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X_new, y)\n",
    "    \n",
    "    X_train_smote, X_val_smote, y_train_smote, y_val_smote = train_test_split(X_resampled_smote, y_resampled_smote, test_size=0.2, random_state=0)\n",
    "    X_train_adasyn, X_val_adasyn, y_train_adasyn, y_val_adasyn = train_test_split(X_resampled_adasyn, y_resampled_adasyn, test_size=0.2, random_state=0)\n",
    "\n",
    "    logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    logreg_model.fit(X_train_smote, y_train_smote)\n",
    "    logreg_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "    \n",
    "    y_pred = logreg_model.predict(X_val)\n",
    "    \n",
    "    accuracy_original = accuracy_score(y_val, y_pred)\n",
    "    conf_matrix_original = confusion_matrix(y_val, y_pred)\n",
    "    f1_original = f1_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_original}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_original)\n",
    "    print(f\"F1 Score: {f1_original}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "# compare result\n",
    "print(\"Original data:\")\n",
    "train(X.columns)\n",
    "print()\n",
    "print(\"filtered_mutual_info:\")\n",
    "train(selected_features_mutualinfo)\n",
    "print()\n",
    "print(\"filtered_rfe:\")\n",
    "train(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a083d32-721a-41bc-a18b-ace7d3cbd659",
   "metadata": {},
   "source": [
    "2. k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353d34e2-527d-4fc6-988e-911faa1dd61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Average Accuracy: 0.16160267111853088\n",
      "Average Confusion Matrix:\n",
      "[[568.6 121.2]\n",
      " [ 16.8  12.2]]\n",
      "Average F1 Score: 0.030049261083743846\n",
      "Average precision Score: 0.018290854572713643\n",
      "Average recall Score: 0.08413793103448276\n",
      "\n",
      "Results:\n",
      "Average Accuracy: 0.32487479131886476\n",
      "Average Confusion Matrix:\n",
      "[[1140.6  239. ]\n",
      " [  31.    27. ]]\n",
      "Average F1 Score: 0.06668292445008048\n",
      "Average precision Score: 0.040613629836665374\n",
      "Average recall Score: 0.18620689655172415\n",
      "\n",
      "Results:\n",
      "Average Accuracy: 0.4882025598219254\n",
      "Average Confusion Matrix:\n",
      "[[1718.8  354.4]\n",
      " [  47.4   35.8]]\n",
      "Average F1 Score: 0.09024383475797874\n",
      "Average precision Score: 0.05478432226822737\n",
      "Average recall Score: 0.256048166392994\n",
      "\n",
      "Results:\n",
      "Average Accuracy: 0.6506956037840845\n",
      "Average Confusion Matrix:\n",
      "[[2290.6  472.6]\n",
      " [  64.    48. ]]\n",
      "Average F1 Score: 0.12089710108963705\n",
      "Average precision Score: 0.07349597870994516\n",
      "Average recall Score: 0.3407703886152162\n",
      "\n",
      "Results:\n",
      "Average Accuracy: 0.8100723427935448\n",
      "Average Confusion Matrix:\n",
      "[[2848.6  603.8]\n",
      " [  78.8   62.8]]\n",
      "Average F1 Score: 0.15461008514430677\n",
      "Average precision Score: 0.09376995131268488\n",
      "Average recall Score: 0.4407703886152162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store performance metrics for Decision Tree\n",
    "accuracy_scores = []\n",
    "conf_matrix_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform K-fold cross-validation for both models\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    smote = SMOTE(random_state=0)\n",
    "    adasyn = ADASYN(random_state=0)\n",
    "\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    X_train_adasyn, y_train_adasyn = smote.fit_resample(X_train, y_train)    \n",
    "\n",
    "    logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    logreg_model.fit(X_train_smote, y_train_smote)\n",
    "    logreg_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "    y_pred = logreg_model.predict(X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    conf_matrix_scores.append(conf_matrix)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    average_accuracy = sum(accuracy_scores) / num_folds\n",
    "    average_conf_matrix = sum(conf_matrix_scores) / num_folds\n",
    "    average_f1 = sum(f1_scores) / num_folds\n",
    "    average_precision = sum(precision_scores) / num_folds\n",
    "    average_recall = sum(recall_scores) / num_folds\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(f\"Average Accuracy: {average_accuracy}\")\n",
    "    print(\"Average Confusion Matrix:\")\n",
    "    print(average_conf_matrix)\n",
    "    print(f\"Average F1 Score: {average_f1}\")\n",
    "    print(f\"Average precision Score: {average_precision}\")\n",
    "    print(f\"Average recall Score: {average_recall}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c23f50-7723-4b58-bb65-c0012a78515d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
