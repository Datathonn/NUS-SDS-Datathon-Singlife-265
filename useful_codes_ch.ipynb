{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa39ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_parquet('./data/catB_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c9bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature Age\n",
    "df = df[df['cltdob_fix']!='None']\n",
    "df['cltdob_fix'] = pd.to_datetime(df.iloc[:, 6], format ='mixed')\n",
    "df['age'] = 2024-df['cltdob_fix'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8496c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Column\n",
    "df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].fillna(0)\n",
    "y = df[\"f_purchase_lh\"]\n",
    "\n",
    "# All features \n",
    "X = df.drop(columns=['f_purchase_lh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669489f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split numerical and non-numerical columns\n",
    "numeric_cols = X.select_dtypes(include=[\"int32\", \"int64\", \"float64\"]).columns\n",
    "X_numeric = X[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2bf6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Low-Variance Numerical Variables\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(0.05))\n",
    "sel.fit(X_numeric)\n",
    "X_numeric = X_numeric[numeric_cols[sel.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86aaaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in numeric columns with the median value\n",
    "X_numeric = X_numeric.apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ec0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with selected non_categorical values\n",
    "temp = pd.get_dummies(X[['cltsex_fix', 'stat_flag']], dtype=float)\n",
    "X = pd.concat([X_numeric, temp, df['age']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a65915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af8049dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for replacement for categorical data (not hot encoding)\n",
    "mapping = {\n",
    "    None: -1,\n",
    "    'E.BELOW30K': 0,\n",
    "    'D.30K-60K': 1,\n",
    "    'C.60K-100K': 2,\n",
    "    'B.100K-200K': 3,\n",
    "    'A.ABOVE200K': 4,\n",
    "}\n",
    "\n",
    "# Replace values based on the mapping\n",
    "df['annual_income_est'] = df['annual_income_est'].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1be1ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    17970.000000\n",
      "mean         0.039399\n",
      "std          0.194548\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: f_purchase_lh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c990956",
   "metadata": {},
   "source": [
    "Select related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0bfb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([X,y],axis=1)\n",
    "#print(df_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae306a3",
   "metadata": {},
   "source": [
    "Select based on mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c06eab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mutual_info_values = mutual_info_classif(X, y, discrete_features=[False]*X.shape[1])\n",
    "\n",
    "threshold = 0.005\n",
    "selected_features = X.columns[mutual_info_values > threshold]\n",
    "\n",
    "df_new_selected = pd.concat([X[selected_features],y],axis=1)\n",
    "print(len(selected_features))\n",
    "#print(df_new_selected.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcab775",
   "metadata": {},
   "source": [
    "Select based on feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5472a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "                          Feature  Importance\n",
      "4                   recency_lapse    0.247752\n",
      "3   n_months_last_bought_products    0.238608\n",
      "6                tot_inforce_pols    0.154182\n",
      "14                cltsex_fix_Male    0.052967\n",
      "13                recency_giclaim    0.051537\n",
      "5                  recency_cancel    0.050193\n",
      "8                   f_hold_507c37    0.041749\n",
      "10                       f_retail    0.037333\n",
      "11    n_months_since_visit_affcon    0.036229\n",
      "12    recency_hlthclaim_unsuccess    0.034832\n",
      "0                     is_valid_dm    0.020149\n",
      "9                f_ever_bought_gi    0.013077\n",
      "1                  is_valid_email    0.009628\n",
      "2                        is_sg_pr    0.006082\n",
      "7                 tot_cancel_pols    0.005682\n",
      "Test Mean Squared Error (Random Forest): 0.03789882993546852\n",
      "Test R-squared (Random Forest): 0.02756219434665852\n",
      "['recency_lapse', 'n_months_last_bought_products', 'tot_inforce_pols', 'cltsex_fix_Male', 'recency_giclaim', 'recency_cancel', 'f_hold_507c37', 'f_retail']\n",
      "Index(['recency_lapse', 'n_months_last_bought_products', 'tot_inforce_pols',\n",
      "       'cltsex_fix_Male', 'recency_giclaim', 'recency_cancel', 'f_hold_507c37',\n",
      "       'f_retail', 'f_purchase_lh'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "X_new = df_new_selected.drop(columns=['f_purchase_lh'])\n",
    "y_new = df_new_selected['f_purchase_lh']\n",
    "\n",
    "X_new_train, X_new_val, y_new_train, y_new_val = train_test_split(X_new, y_new, test_size=0.2, random_state=0)\n",
    "\n",
    "rf_model.fit(X_new_train, y_new_train)\n",
    "\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': X_new_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n",
    "\n",
    "y_pred_test = rf_model.predict(X_new_val)\n",
    "mse_test_rf = mean_squared_error(y_new_val, y_pred_test)\n",
    "r2_test_rf = r2_score(y_new_val, y_pred_test)\n",
    "\n",
    "print(f'Test Mean Squared Error (Random Forest): {mse_test_rf}')\n",
    "print(f'Test R-squared (Random Forest): {r2_test_rf}')\n",
    "\n",
    "selected_features2 = importance_df.head(8)['Feature'].tolist()\n",
    "print(selected_features2)\n",
    "df_new_selected2 = df_new_selected[selected_features2+['f_purchase_lh']]\n",
    "print(df_new_selected2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64973e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['recency_lapse', 'n_months_last_bought_products', 'tot_inforce_pols',\n",
      "       'cltsex_fix_Male', 'recency_giclaim', 'recency_cancel', 'f_hold_507c37',\n",
      "       'f_retail'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_new = df_new_selected2.drop(columns=['f_purchase_lh'])\n",
    "y_new = df_new_selected2['f_purchase_lh']\n",
    "print(X_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4eac1",
   "metadata": {},
   "source": [
    "resampling - original data is imbalanced (too many 0 very 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c4a77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9993c",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f37bf",
   "metadata": {},
   "source": [
    "normal logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d5ce58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9579855314412911\n",
      "Confusion Matrix:\n",
      "[[3442    6]\n",
      " [ 145    1]]\n",
      "F1 Score: 0.013071895424836602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = logreg_model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d5b3c",
   "metadata": {},
   "source": [
    "resampled logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b82dfa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on Original Data:\n",
      "Accuracy: 0.8010573177518086\n",
      "Confusion Matrix:\n",
      "[[2814  634]\n",
      " [  81   65]]\n",
      "F1 Score: 0.15384615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\n",
    "\n",
    "adasyn = ADASYN(random_state=0)\n",
    "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X, y)\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# SMOTE\n",
    "X_train_smote, X_val_smote, y_train_smote, y_val_smote = train_test_split(X_resampled_smote, y_resampled_smote, test_size=0.2, random_state=0)\n",
    "logreg_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# ADASYN\n",
    "X_train_adasyn, X_val_adasyn, y_train_adasyn, y_val_adasyn = train_test_split(X_resampled_adasyn, y_resampled_adasyn, test_size=0.2, random_state=0)\n",
    "logreg_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Assuming X and y are your original features and target\n",
    "X_train_original, X_val_original, y_train_original, y_val_original = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "y_val_pred_original = logreg_model.predict(X_val_original)\n",
    "\n",
    "accuracy_original = accuracy_score(y_val_original, y_val_pred_original)\n",
    "conf_matrix_original = confusion_matrix(y_val_original, y_val_pred_original)\n",
    "f1_original = f1_score(y_val_original, y_val_pred_original)\n",
    "\n",
    "print(\"Results on Original Data:\")\n",
    "print(f\"Accuracy: {accuracy_original}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_original)\n",
    "print(f\"F1 Score: {f1_original}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623576a",
   "metadata": {},
   "source": [
    "resampled logistic with cross-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8cc608f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results with SMOTE:\n",
      "F1 Scores: [0.78892342 0.78308824 0.78727634 0.79426381 0.79495179]\n",
      "Mean F1 Score: 0.7897007193404375\n",
      "\n",
      "Cross-Validation Results with ADASYN:\n",
      "F1 Scores: [0.77697228 0.7727662  0.77772957 0.78109523 0.78398163]\n",
      "Mean F1 Score: 0.7785089828542116\n",
      "\n",
      "Results on Original Data:\n",
      "Accuracy: 0.7337228714524207\n",
      "Confusion Matrix:\n",
      "[[2557  891]\n",
      " [  66   80]]\n",
      "F1 Score: 0.14324082363473592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# SMOTE\n",
    "cv_smote = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "cross_val_results_smote = cross_val_score(logreg_model, X_resampled_smote, y_resampled_smote, cv=cv_smote, scoring='f1')\n",
    "\n",
    "# ADASYN\n",
    "cv_adasyn = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "cross_val_results_adasyn = cross_val_score(logreg_model, X_resampled_adasyn, y_resampled_adasyn, cv=cv_adasyn, scoring='f1')\n",
    "\n",
    "print(\"Cross-Validation Results with SMOTE:\")\n",
    "print(f\"F1 Scores: {cross_val_results_smote}\")\n",
    "print(f\"Mean F1 Score: {cross_val_results_smote.mean()}\")\n",
    "\n",
    "print(\"\\nCross-Validation Results with ADASYN:\")\n",
    "print(f\"F1 Scores: {cross_val_results_adasyn}\")\n",
    "print(f\"Mean F1 Score: {cross_val_results_adasyn.mean()}\")\n",
    "\n",
    "y_val_pred_original = logreg_model.predict(X_val_original)\n",
    "\n",
    "accuracy_original = accuracy_score(y_val_original, y_val_pred_original)\n",
    "conf_matrix_original = confusion_matrix(y_val_original, y_val_pred_original)\n",
    "f1_original = f1_score(y_val_original, y_val_pred_original)\n",
    "\n",
    "print(\"\\nResults on Original Data:\")\n",
    "print(f\"Accuracy: {accuracy_original}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_original)\n",
    "print(f\"F1 Score: {f1_original}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9db8f",
   "metadata": {},
   "source": [
    "logsitic with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cc1a40c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9590984974958264\n",
      "Confusion Matrix:\n",
      "[[3447    1]\n",
      " [ 146    0]]\n",
      "F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "X_new = df_new_selected2.drop(columns=['f_purchase_lh'])\n",
    "y_new = df_new_selected2['f_purchase_lh']\n",
    "X_new_train, X_new_val, y_new_train, y_new_val = train_test_split(X_new, y_new, test_size=0.2, random_state=0)\n",
    "logreg_model.fit(X_new_train, y_new_train)\n",
    "\n",
    "y_val_pred = logreg_model.predict(X_new_val)\n",
    "\n",
    "accuracy = accuracy_score(y_new_val, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_new_val, y_val_pred)\n",
    "f1 = f1_score(y_new_val, y_val_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "#accuracy_score(y_val, [0]*3594)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb52a12",
   "metadata": {},
   "source": [
    "adjusted logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "75bd9f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Custom Threshold: 0.9426822481914302\n",
      "Confusion Matrix with Custom Threshold:\n",
      "[[3350   98]\n",
      " [ 108   38]]\n",
      "F1 Score with Custom Threshold: 0.2695035460992908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob = logreg_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# custom threshold\n",
    "custom_threshold = 0.15\n",
    "y_val_pred_custom = (y_val_prob > custom_threshold).astype(int)\n",
    "\n",
    "accuracy_custom = accuracy_score(y_val, y_val_pred_custom)\n",
    "conf_matrix_custom = confusion_matrix(y_val, y_val_pred_custom)\n",
    "f1_custom = f1_score(y_val, y_val_pred_custom)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy with Custom Threshold: {accuracy_custom}\")\n",
    "print(\"Confusion Matrix with Custom Threshold:\")\n",
    "print(conf_matrix_custom)\n",
    "print(f\"F1 Score with Custom Threshold: {f1_custom}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6a9415",
   "metadata": {},
   "source": [
    "adjusted logistic with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58bfae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy with Custom Threshold: 0.9380218903065852\n",
      "Average Confusion Matrix with Custom Threshold:\n",
      "[[2669.    93.8]\n",
      " [  84.4   28. ]]\n",
      "Average F1 Score with Custom Threshold: 0.23861971868864423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# custom threshold\n",
    "custom_threshold = 0.15\n",
    "\n",
    "# cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "accuracy_scores = []\n",
    "conf_matrices = []\n",
    "f1_scores = []\n",
    "\n",
    "# cross-validation\n",
    "for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    logreg_model.fit(X_train_fold, y_train_fold)\n",
    "    y_val_prob = logreg_model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "    y_val_pred_custom = (y_val_prob > custom_threshold).astype(int)\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_val_pred_custom)\n",
    "    conf_matrix_fold = confusion_matrix(y_val_fold, y_val_pred_custom)\n",
    "    f1_fold = f1_score(y_val_fold, y_val_pred_custom)\n",
    "\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "    conf_matrices.append(conf_matrix_fold)\n",
    "    f1_scores.append(f1_fold)\n",
    "\n",
    "print(f\"Average Accuracy with Custom Threshold: {sum(accuracy_scores) / len(accuracy_scores)}\")\n",
    "print(\"Average Confusion Matrix with Custom Threshold:\")\n",
    "print(sum(conf_matrices) / len(conf_matrices))\n",
    "print(f\"Average F1 Score with Custom Threshold: {sum(f1_scores) / len(f1_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d470f4",
   "metadata": {},
   "source": [
    "adjusted logistic with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fff499ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Custom Threshold: 0.9501947690595437\n",
      "Confusion Matrix with Custom Threshold:\n",
      "[[3393   55]\n",
      " [ 124   22]]\n",
      "F1 Score with Custom Threshold: 0.19730941704035873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ch8765\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y_new, test_size=0.2, random_state=0)\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_val_prob = logreg_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "custom_threshold = 0.15\n",
    "y_val_pred_custom = (y_val_prob > custom_threshold).astype(int)\n",
    "\n",
    "accuracy_custom = accuracy_score(y_val, y_val_pred_custom)\n",
    "conf_matrix_custom = confusion_matrix(y_val, y_val_pred_custom)\n",
    "f1_custom = f1_score(y_val, y_val_pred_custom)\n",
    "\n",
    "print(f\"Accuracy with Custom Threshold: {accuracy_custom}\")\n",
    "print(\"Confusion Matrix with Custom Threshold:\")\n",
    "print(conf_matrix_custom)\n",
    "print(f\"F1 Score with Custom Threshold: {f1_custom}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36aedfa",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e46730",
   "metadata": {},
   "source": [
    "normal random forest with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43bd35a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.9301613800779076\n",
      "Confusion Matrix:\n",
      "[[3318  130]\n",
      " [ 121   25]]\n",
      "F1 Score: 0.16611295681063123\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9596549805230941\n",
      "Confusion Matrix:\n",
      "[[3445    3]\n",
      " [ 142    4]]\n",
      "F1 Score: 0.05228758169934641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=0,class_weight='balanced')\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_dt = dt_model.predict(X_val)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_val, y_val_pred_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_val, y_val_pred_dt)\n",
    "f1_dt = f1_score(y_val, y_val_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_dt)\n",
    "print(f\"F1 Score: {f1_dt}\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0,class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_val, y_val_pred_rf)\n",
    "f1_rf = f1_score(y_val, y_val_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(f\"F1 Score: {f1_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce841332",
   "metadata": {},
   "source": [
    "random forest & decision tree with custom threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca8c562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.9301613800779076\n",
      "Confusion Matrix:\n",
      "[[3318  130]\n",
      " [ 121   25]]\n",
      "F1 Score: 0.16611295681063123\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9354479688369505\n",
      "Confusion Matrix:\n",
      "[[3316  132]\n",
      " [ 100   46]]\n",
      "F1 Score: 0.2839506172839506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=0,class_weight='balanced')\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob_dt = dt_model.predict_proba(X_val)[:, 1]\n",
    "custom_threshold = 0.15  # Adjust as needed\n",
    "y_val_pred_custom_dt = (y_val_prob_dt > custom_threshold).astype(int)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_val, y_val_pred_custom_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_val, y_val_pred_custom_dt)\n",
    "f1_dt = f1_score(y_val, y_val_pred_custom_dt)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_dt)\n",
    "print(f\"F1 Score: {f1_dt}\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0,class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob_rf = rf_model.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_custom_rf = (y_val_prob_rf > custom_threshold).astype(int)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_val, y_val_pred_custom_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_val, y_val_pred_custom_rf)\n",
    "f1_rf = f1_score(y_val, y_val_pred_custom_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(f\"F1 Score: {f1_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902f516",
   "metadata": {},
   "source": [
    "custom rf & dt with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1767b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.9301613800779076\n",
      "Confusion Matrix:\n",
      "[[3318  130]\n",
      " [ 121   25]]\n",
      "F1 Score: 0.16611295681063123\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9354479688369505\n",
      "Confusion Matrix:\n",
      "[[3316  132]\n",
      " [ 100   46]]\n",
      "F1 Score: 0.2839506172839506\n",
      "\n",
      "Decision Tree Cross-Validation Results:\n",
      "Average F1 Score: 0.18909699544002626\n",
      "\n",
      "Random Forest Cross-Validation Results:\n",
      "Average F1 Score: 0.0510024022911057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob_dt = dt_model.predict_proba(X_val)[:, 1]\n",
    "custom_threshold = 0.15 \n",
    "y_val_pred_custom_dt = (y_val_prob_dt > custom_threshold).astype(int)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_val, y_val_pred_custom_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_val, y_val_pred_custom_dt)\n",
    "f1_dt = f1_score(y_val, y_val_pred_custom_dt)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_dt)\n",
    "print(f\"F1 Score: {f1_dt}\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob_rf = rf_model.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_custom_rf = (y_val_prob_rf > custom_threshold).astype(int)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_val, y_val_pred_custom_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_val, y_val_pred_custom_rf)\n",
    "f1_rf = f1_score(y_val, y_val_pred_custom_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(f\"F1 Score: {f1_rf}\")\n",
    "\n",
    "\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Decision Tree Cross-Validation Results\n",
    "cv_scores_dt = cross_val_score(dt_model, X, y, cv=5, scoring=scorer)\n",
    "print(\"\\nDecision Tree Cross-Validation Results:\")\n",
    "print(f\"Average F1 Score: {np.mean(cv_scores_dt)}\")\n",
    "\n",
    "# Random Forest Cross-Validation Results\n",
    "cv_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring=scorer)\n",
    "print(\"\\nRandom Forest Cross-Validation Results:\")\n",
    "print(f\"Average F1 Score: {np.mean(cv_scores_rf)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e66525",
   "metadata": {},
   "source": [
    "random forest and decision tree with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1478bcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.8667223149693934\n",
      "Confusion Matrix:\n",
      "[[3083  365]\n",
      " [ 114   32]]\n",
      "F1 Score: 0.11786372007366484\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9151363383416806\n",
      "Confusion Matrix:\n",
      "[[3268  180]\n",
      " [ 125   21]]\n",
      "F1 Score: 0.12103746397694524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y_new, test_size=0.2, random_state=0)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=0,class_weight='balanced')\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_dt = dt_model.predict(X_val)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_val, y_val_pred_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_val, y_val_pred_dt)\n",
    "f1_dt = f1_score(y_val, y_val_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_dt)\n",
    "print(f\"F1 Score: {f1_dt}\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0,class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_val, y_val_pred_rf)\n",
    "f1_rf = f1_score(y_val, y_val_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(f\"F1 Score: {f1_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a7880",
   "metadata": {},
   "source": [
    "dt rf with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bee1c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Best Hyperparameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Accuracy: 0.8825820812465219\n",
      "Confusion Matrix:\n",
      "[[3134  314]\n",
      " [ 108   38]]\n",
      "F1 Score: 0.15261044176706826\n",
      "\n",
      "Random Forest Results:\n",
      "Best Hyperparameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Accuracy: 0.9471341124095715\n",
      "Confusion Matrix:\n",
      "[[3367   81]\n",
      " [ 109   37]]\n",
      "F1 Score: 0.28030303030303033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0, class_weight='balanced')\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid Search for Decision Tree\n",
    "grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=param_grid, scoring='f1', cv=3)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Grid Search for Random Forest\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='f1', cv=3)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# hyperparameters\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "y_val_pred_dt = grid_search_dt.best_estimator_.predict(X_val)\n",
    "y_val_pred_rf = grid_search_rf.best_estimator_.predict(X_val)\n",
    "\n",
    "# Decision Tree\n",
    "accuracy_dt = accuracy_score(y_val, y_val_pred_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_val, y_val_pred_dt)\n",
    "f1_dt = f1_score(y_val, y_val_pred_dt)\n",
    "\n",
    "# Random Forest\n",
    "accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_val, y_val_pred_rf)\n",
    "f1_rf = f1_score(y_val, y_val_pred_rf)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_dt}\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_dt)\n",
    "print(f\"F1 Score: {f1_dt}\")\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_rf}\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(f\"F1 Score: {f1_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ccef1",
   "metadata": {},
   "source": [
    "dt & rf with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "518f2098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Best Hyperparameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "Accuracy: 0.889259877573734\n",
      "Confusion Matrix:\n",
      "[[3158  290]\n",
      " [ 108   38]]\n",
      "F1 Score: 0.16033755274261605\n",
      "\n",
      "Random Forest Results:\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Accuracy: 0.9020589872008904\n",
      "Confusion Matrix:\n",
      "[[3181  267]\n",
      " [  85   61]]\n",
      "F1 Score: 0.25738396624472576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0, class_weight='balanced')\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "# Random Search for Decision Tree\n",
    "random_search_dt = RandomizedSearchCV(estimator=dt_model, param_distributions=param_dist, scoring='f1', cv=3, n_iter=10, random_state=0)\n",
    "random_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Random Search for Random Forest\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, scoring='f1', cv=3, n_iter=10, random_state=0)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# hyperparameters\n",
    "best_params_dt = random_search_dt.best_params_\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "y_val_pred_dt = random_search_dt.best_estimator_.predict(X_val)\n",
    "y_val_pred_rf = random_search_rf.best_estimator_.predict(X_val)\n",
    "\n",
    "# Decision Tree\n",
    "accuracy_dt = accuracy_score(y_val, y_val_pred_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_val, y_val_pred_dt)\n",
    "f1_dt = f1_score(y_val, y_val_pred_dt)\n",
    "\n",
    "# Random Forest\n",
    "accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_val, y_val_pred_rf)\n",
    "f1_rf = f1_score(y_val, y_val_pred_rf)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_dt}\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_dt)\n",
    "print(f\"F1 Score: {f1_dt}\")\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_rf}\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(f\"F1 Score: {f1_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993fe00",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "97c878ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Custom Threshold (SVM): 0.9593767390094602\n",
      "Confusion Matrix without Custom Threshold (SVM):\n",
      "[[3448    0]\n",
      " [ 146    0]]\n",
      "F1 Score without Custom Threshold (SVM): 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "svm_model = SVC(probability=True)  \n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob_svm = svm_model.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_svm = svm_model.predict(X_val)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_val, y_val_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_val, y_val_pred_svm)\n",
    "f1_svm = f1_score(y_val, y_val_pred_svm)\n",
    "\n",
    "print(f\"Accuracy without Custom Threshold (SVM): {accuracy_svm}\")\n",
    "print(\"Confusion Matrix without Custom Threshold (SVM):\")\n",
    "print(conf_matrix_svm)\n",
    "print(f\"F1 Score without Custom Threshold (SVM): {f1_svm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5086812",
   "metadata": {},
   "source": [
    "svm with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b821dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Custom Threshold (SVM): 0.8196994991652755\n",
      "Confusion Matrix without Custom Threshold (SVM):\n",
      "[[2889  559]\n",
      " [  89   57]]\n",
      "F1 Score without Custom Threshold (SVM): 0.14960629921259844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=0.1, probability=True)\n",
    "svm_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_val_prob_svm = svm_model.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_svm = svm_model.predict(X_val)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_val, y_val_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_val, y_val_pred_svm)\n",
    "f1_svm = f1_score(y_val, y_val_pred_svm)\n",
    "\n",
    "print(f\"Accuracy without Custom Threshold (SVM): {accuracy_svm}\")\n",
    "print(\"Confusion Matrix without Custom Threshold (SVM):\")\n",
    "print(conf_matrix_svm)\n",
    "print(f\"F1 Score without Custom Threshold (SVM): {f1_svm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7afa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
